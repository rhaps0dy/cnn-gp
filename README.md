# "Deep CNNs as shallow GPs" in Pytorch
Code for "Deep Convolutional Networks as shallow Gaussian Processes"
([arXiv](https://arxiv.org/abs/1808.05587),
[other material](https://agarri.ga/publication/convnets-as-gps/)), by
[Adri√† Garriga-Alonso](https://agarri.ga/),
[Laurence Aitchison](http://www.gatsby.ucl.ac.uk/~laurence/) and
[Carl Edward Rasmussen](http://mlg.eng.cam.ac.uk/carl/).

The most extensively used libraries
are [PyTorch](https://pytorch.org/), [NumPy](https://www.numpy.org/) and
[H5Py](http://www.h5py.org/), check `requirements.txt` for the rest.

# The `cnn_gp` package
This library allows you to very easily write down neural network architectures,
and get the kernels corresponding to their equivalent GPs. We can easily build
`Sequential` architectures. For example, a 3-layer convolutional network with a
dense layer at the end is:

```python
from cnn_gp import Sequential, Conv2d, ReLU

model = Sequential(
    Conv2d(kernel_size=3),
    ReLU(),
    Conv2d(kernel_size=3, stride=2),
    ReLU(),
    Conv2d(kernel_size=14, padding=0),  # equivalent to a dense layer
)
```
Optionally call `model = model.cuda()` to use the GPU.

Then, we can compute the kernel between batches of input images:
```python
import torch
# X and Z have shape [N_images, N_channels, img_width, img_height]
X = torch.randn(2, 3, 28, 28)
Z = torch.randn(2, 3, 28, 28)

Kxx = model(X)
Kxx = model(X, X, same=True)

Kxz = model(X, Z)

# diagonal of Kxx matrix above
Kxx_diag = model(X, diag=True)
```

We can also instantiate randomly initialized neural networks that have the
architecture corresponding to the kernel.
```python
network = model.nn(channels=16, in_channels=3, out_channels=10)
isinstance(network, torch.nn.Module)  # evaluates to True

f_X = network(X)  # evaluates network at X
```
Calling `model.nn` will give us an instance of the network above that can do 10-class
classification. It accepts inputs that are RGB images (3 channels) of size
28x28. We can then train this neural network as we would any normal Pytorch
model.

## Installation
It is possible to install the `cnn_gp` package without any of the dependencies
that are needed for the experiments. Just run
```sh
pip install -e .
```
from the root directory of this same repository.

## Current limitations
Dense layers are not implemented. The way to simulate them is to have a
convolutional layer with `padding=0`, and with `kernel_size` as large as the
activations in the previous layer.

# Replicating the experiments

First install the packages in `requirements.txt`. To run each of the
experiments, first take a look at the files `exp_mnist_resnet/run.bash` or
`exp_random_nn/run.bash`. Edit the configuration variables near the top
appropriately. Then, run one of the files from the root of the directory, for
example:

```bash
bash ./exp_mnist_resnet/run.bash
```

## Experiment 1: classify MNIST

Here are the test errors for the best GPs corresponding to the NN architectures
reported in the paper.

 Name in paper | Config file | Validation error | Test error
 --------------|-------------|------------------|----------
ConvNet GP | `mnist_paper_convnet_gp` | 0.71% | 1.03%
Residual CNN GP | `mnist_paper_residual_cnn_gp` | 0.72% | 0.96%
ResNet GP | `mnist_as_tf` | 0.68% | 0.84%

<details>
  <summary>(click to expand) Architecture for ConvNet GP</summary>

  ```python
  var_bias = 7.86
  var_weight = 2.79

  initial_model = Sequential(
      Conv2d(kernel_size=7, padding="same", var_weight=var_weight * 7**2, var_bias=var_bias),
      ReLU(),
      Conv2d(kernel_size=7, padding="same", var_weight=var_weight * 7**2, var_bias=var_bias),
      ReLU(),
      Conv2d(kernel_size=7, padding="same", var_weight=var_weight * 7**2, var_bias=var_bias),
      ReLU(),
      Conv2d(kernel_size=7, padding="same", var_weight=var_weight * 7**2, var_bias=var_bias),
      ReLU(),
      Conv2d(kernel_size=7, padding="same", var_weight=var_weight * 7**2, var_bias=var_bias),
      ReLU(),
      Conv2d(kernel_size=7, padding="same", var_weight=var_weight * 7**2, var_bias=var_bias),
      ReLU(),
      Conv2d(kernel_size=7, padding="same", var_weight=var_weight * 7**2, var_bias=var_bias),
      ReLU(),  # Total 7 layers before dense

      Conv2d(kernel_size=28, padding=0, var_weight=var_weight, var_bias=var_bias),
  ```
</details>
<details>
  <summary>(click to expand) Architecture for Residual CNN GP</summary>

  ```python
  var_bias = 4.69
  var_weight = 7.27
  initial_model = Sequential(
      *(Sum([
          Sequential(),
          Sequential(
              Conv2d(kernel_size=4, padding="same", var_weight=var_weight * 4**2,
                  var_bias=var_bias),
              ReLU(),
          )]) for _ in range(8)),
      Conv2d(kernel_size=4, padding="same", var_weight=var_weight * 4**2,
          var_bias=var_bias),
      ReLU(),
      Conv2d(kernel_size=28, padding=0, var_weight=var_weight,
          var_bias=var_bias),
  )
  ```
</details>

<details>
  <summary>(click to expand) Architecture for ResNet GP</summary>

  ```python
  initial_model = Sequential(
      Conv2d(kernel_size=3),

      # Big resnet block #1
      resnet_block(stride=1, projection_shortcut=True,  multiplier=1),
      resnet_block(stride=1, projection_shortcut=False, multiplier=1),
      resnet_block(stride=1, projection_shortcut=False, multiplier=1),
      resnet_block(stride=1, projection_shortcut=False, multiplier=1),
      resnet_block(stride=1, projection_shortcut=False, multiplier=1),

      # Big resnet block #2
      resnet_block(stride=2, projection_shortcut=True,  multiplier=2),
      resnet_block(stride=1, projection_shortcut=False, multiplier=2),
      resnet_block(stride=1, projection_shortcut=False, multiplier=2),
      resnet_block(stride=1, projection_shortcut=False, multiplier=2),
      resnet_block(stride=1, projection_shortcut=False, multiplier=2),

      # Big resnet block #3
      resnet_block(stride=2, projection_shortcut=True,  multiplier=4),
      resnet_block(stride=1, projection_shortcut=False, multiplier=4),
      resnet_block(stride=1, projection_shortcut=False, multiplier=4),
      resnet_block(stride=1, projection_shortcut=False, multiplier=4),
      resnet_block(stride=1, projection_shortcut=False, multiplier=4),

      # No nonlinearity here, the next Conv2d substitutes the average pooling
      Conv2d(kernel_size=7, padding=0, in_channel_multiplier=4,
             out_channel_multiplier=4),
      ReLU(),
      Conv2d(kernel_size=1, padding=0, in_channel_multiplier=4),
  )
  ```
</details>

## Experiment 2: Check that networks converge to a Gaussian process
In the paper, only ResNet-32 GP is presented. This is why a bug when
constructing the Residual CNN GP was originally not caught. More details in the
relevant subsection.
### ResNet-32 GP
![Resnet-32 GP](/exp_random_nn/mnist_as_tf/figure.png)
### ConvNet GP
![Resnet-32 GP](/exp_random_nn/mnist_paper_convnet_gp/figure.png)
### Residual CNN GP
The best randomly-searched ResNet reported in the paper.

In the original paper there is a bug. This network sums together layers after
the ReLU nonlinearity, which are not Gaussian, and also do not have mean 0. As
a result, the overall network does not converge to a Gaussian process. The
defined kernel is still valid, even if it doesn't correspond to a NN.

In the interest of making the results replicable, we have replicated this bug
as well.

The correct way to use ResNets is to sum things after a Conv2d layer, see for
example the `resnet_block` in [`cnn_gp/kernels.py`](/cnn_gp/kernels.py).

![Resnet-32 GP](/exp_random_nn/mnist_paper_residual_cnn_gp/figure.png)


# BibTex citation record
Note: the version in arXiv is slightly newer and contains information about
which hyperparameters turned out to be the most effective for each architecture.

```bibtex
@inproceedings{garriga2018infiniteconv,
  author    = {Adri{\`{a}} Garriga{-}Alonso and
               Carl Edward Rasmussen and
               Laurence Aitchison},
  title     = {Deep Convolutional Networks as shallow {G}aussian Processes},
  booktitle = {7th International Conference on Learning Representations},
  year      = {2019},
  url       = {https://openreview.net/forum?id=Bklfsi0cKm},
  archivePrefix = {arXiv},
  eprint = {1808.05587},
}
```
